{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 크롤링\n",
    "\n",
    "#### requests\n",
    "\n",
    "백그라운드에서 웹 크롤링을 진행.  \n",
    "\n",
    "    requests.get(\"url\")\n",
    "    \n",
    "입력한 URL을 호출함.\n",
    "\n",
    "**<HTTP 응답 번호>**\n",
    "- 200은 성공(205: ???)  \n",
    "- 300번대는 리다이렉션 메시지  \n",
    "- 400번대는 오류 메시지(403: 권한 없음, 404: 존재하지 않는 페이지)\n",
    "\n",
    "웹페이지 개발자 도구 이용  \n",
    "보통은 개발자 도구 페이지의 개체를 마우스 우클릭하면 나오는 XPath를 사용하여 코드 작성.\n",
    "\n",
    "#### bs4\n",
    "\n",
    "con.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib as ulb\n",
    "import requests as rqs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = \"https://ko.wikipedia.org/wiki/조선_세종\"\n",
    "\n",
    "a = rqs.get(\"http://www.naver.com\")\n",
    "b = bs(a.content, \"lxml\")\n",
    "\n",
    "lst_kw = b.find_all(name = \"a\", class_ = \"ah_k\", attr = {\"data-clk\" : \"lve.keyword\"})\n",
    "b\n",
    "# lst_rk = b.fine_all(name = \"span\", class_ = \"ah_r\")\n",
    "\n",
    "# for line in :\n",
    "    # print(line.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬으로 매일 오전 8시, 오후 8시 실시간 검색어를 7일간 크롤링하기.  \n",
    "검색어의 순위 정보도 크롤링돼야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib as ulb\n",
    "import requests as rqs\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://datalab.naver.com/keyword/realtimeList.naver?datetime=2019-05-16T20%3A00%3A00&where=main\n",
      "https://datalab.naver.com/keyword/realtimeList.naver?datetime=2019-05-16T20%3A00%3A00&where=main\n"
     ]
    }
   ],
   "source": [
    "date = [\"2019-05-16\", \"2019-05-17\", \"2019-05-18\", \"2019-05-19\", \"2019-05-20\", \"2019-05-21\", \"2019-05-22\", \"2019-05-23\"]\n",
    "time = [\"08%3A00%3A00\", \"20%3A00%3A00\"]\n",
    "\n",
    "url = \"https://datalab.naver.com/keyword/realtimeList.naver?datetime=%sT%s&where=main\" %(date[0], time[1])\n",
    "print(url)\n",
    "\n",
    "rq_header = {\n",
    "    \"User-Agent\" : (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.134 Safari/537.36 Vivaldi/2.5.1525.40\")\n",
    "}\n",
    "\n",
    "page = rqs.get(url, headers = rq_header)\n",
    "page.encoding = \"utf-8\"\n",
    "print(page.url)\n",
    "# print(page.history)\n",
    "\n",
    "source_page = soup(page.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_sql(d, t, k, r, c, s):\n",
    "    dict_age = {\"all\" : \"전체\", \"10s\" : \"10대\", \"20s\" : \"20대\", \"30s\" : \"30대\", \"40s\" : \"40대\", \"50s\" : \"50대 이상\"}\n",
    "    \n",
    "    dict_time = {\"08%3A00%3A00\": \"08:00\", \"20%3A00%3A00\": \"20:00\"}\n",
    "    \n",
    "    sql = \"\"\"INSERT INTO Search_Keywords(Date, Time, Keyword, Rank, Category, Source)\n",
    "VALUES ('%s', '%s', '%s', '%s', '%s', '%s');\"\"\" %(d, dict_time[t], k, r, dict_age[c], s)\n",
    "        \n",
    "    return sql\n",
    "    \n",
    "    \n",
    "def crawler(dates, times):\n",
    "    rq_header = {\n",
    "    \"User-Agent\" : (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.134 Safari/537.36 Vivaldi/2.5.1525.40\")\n",
    "    }\n",
    "    \n",
    "    ages = [\"all\", \"10s\", \"20s\", \"30s\", \"40s\", \"50s\"]\n",
    "    \n",
    "    for d in dates:  # 일자별로 키워드 수집\n",
    "        for t in times:  # 시간별로 키워드 수집\n",
    "            url = \"https://datalab.naver.com/keyword/realtimeList.naver?datetime=%sT%s&where=main\" %(d, t)\n",
    "            \n",
    "            page = rqs.get(url, headers = rq_header)\n",
    "            page.encoding = \"utf-8\"\n",
    "            \n",
    "            source_page = soup(page.content, \"lxml\")\n",
    "            \n",
    "            for i in range(len(ages)):  # 나이별로 키워드 수집\n",
    "                keywords = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='%s'] span\" %ages[i])\n",
    "                \n",
    "                kwds_txt = []\n",
    "                for j in range(len(keywords)):  # 키워드(텍스트)만 추출하여 txt에 추가\n",
    "                    kwds_txt.append(keywords[j].text)\n",
    "                \n",
    "                for j in range(len(kwds_txt)):\n",
    "                    sql = export_to_sql(d, t, kwds_txt[j], j + 1, ages[i], \"Naver\")  # Date, Time, Keyword, Rank, Category, Source\n",
    "                    cursor.execute(sql)\n",
    "    \n",
    "    print(\"end\")\n",
    "\n",
    "    cnx.commit()\n",
    "    print(\"커밋됨.\")\n",
    "\n",
    "    cnx.close()\n",
    "    print(\"종료됨.\")\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n",
      "커밋됨.\n",
      "종료됨.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = [\"2019-05-16\", \"2019-05-17\", \"2019-05-18\", \"2019-05-19\", \"2019-05-20\", \"2019-05-21\", \"2019-05-22\", \"2019-05-23\"]\n",
    "\n",
    "times = [\"08%3A00%3A00\", \"20%3A00%3A00\"]\n",
    "\n",
    "crawler([\"2019-05-23\"], [\"08%3A00%3A00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['김기태',\n",
       " '유승현',\n",
       " '생생정보통 이피디',\n",
       " '이미자',\n",
       " '도니도니돈까스',\n",
       " '김현아 의원',\n",
       " '한센병',\n",
       " '나이키 사카이',\n",
       " '이재명',\n",
       " '박흥식',\n",
       " '절대그이',\n",
       " '구형',\n",
       " '강유미',\n",
       " '김성수',\n",
       " '누룽지통닭',\n",
       " '엠카운트다운',\n",
       " '이동휘',\n",
       " '드라이카레',\n",
       " '레이디스코드',\n",
       " '문무일']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keywords = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank > .rank_inner *\")\n",
    "# rank = source_page\n",
    "keywords_all = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='all'] span\")\n",
    "\n",
    "res_all = []\n",
    "for i in range(len(keywords_all)):\n",
    "    res_all.append(keywords_all[i].text)\n",
    "\n",
    "res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['김기태',\n",
       " '구형',\n",
       " '에이틴',\n",
       " '김성수',\n",
       " '엠카운트다운',\n",
       " '내신등급계산기',\n",
       " '타미힐피거 반팔',\n",
       " '레이디스코드',\n",
       " '체육대회 머리',\n",
       " '이동휘',\n",
       " '사형 구형',\n",
       " '연애혁명',\n",
       " '브이앱',\n",
       " '강서구 pc방 살인',\n",
       " '네이버티비',\n",
       " '박흥식',\n",
       " 'ebsi 고등',\n",
       " '2019 인하대 축제',\n",
       " '메트로시티 팔찌',\n",
       " '승리 기각']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_10s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='10s'] span\")\n",
    "\n",
    "res_10s = []\n",
    "for i in range(len(keywords_10s)):\n",
    "    res_10s.append(keywords_10s[i].text)\n",
    "\n",
    "res_10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['김기태',\n",
       " '이동휘',\n",
       " '구형',\n",
       " '엠카운트다운',\n",
       " '나이키 사카이',\n",
       " '메이플 인벤',\n",
       " '김성수',\n",
       " '생생정보통 이피디',\n",
       " '강유미',\n",
       " '레이디스코드',\n",
       " '도니도니돈까스',\n",
       " '절대그이',\n",
       " '타미힐피거 반팔',\n",
       " '사형 구형',\n",
       " '박흥식',\n",
       " '승리 기각',\n",
       " '강서구 pc방 살인',\n",
       " '2019 홍대 축제',\n",
       " '유승현',\n",
       " '옥택연']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_20s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='20s'] span\")\n",
    "\n",
    "res_20s = []\n",
    "for i in range(len(keywords_20s)):\n",
    "    res_20s.append(keywords_20s[i].text)\n",
    "\n",
    "res_20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['김기태',\n",
       " '도니도니돈까스',\n",
       " '생생정보통 이피디',\n",
       " '나이키 사카이',\n",
       " '유승현',\n",
       " '절대그이',\n",
       " '강유미',\n",
       " '이재명',\n",
       " '드라이카레',\n",
       " '한센병',\n",
       " '누룽지통닭',\n",
       " '이상화',\n",
       " '박흥식',\n",
       " '송도 사고',\n",
       " '레이디스코드',\n",
       " '장민재',\n",
       " '임지현',\n",
       " '김성수',\n",
       " '이미자',\n",
       " '대왕타르트']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_30s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='30s'] span\")\n",
    "\n",
    "res_30s = []\n",
    "for i in range(len(keywords_30s)):\n",
    "    res_30s.append(keywords_30s[i].text)\n",
    "\n",
    "res_30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['유승현',\n",
       " '생생정보 이피디',\n",
       " '김기태',\n",
       " '한센병',\n",
       " '김현아 의원',\n",
       " '이재명',\n",
       " '도니도니돈까스',\n",
       " '이미자',\n",
       " '박흥식',\n",
       " '누룽지통닭',\n",
       " '절대그이',\n",
       " '드라이카레',\n",
       " '송도 사고',\n",
       " '나이키 사카이',\n",
       " '심재철',\n",
       " '참나무장작구이 누룽지통닭',\n",
       " '대왕타르트',\n",
       " '아이엠넘버포',\n",
       " '생방송투데이',\n",
       " '마라롱샤']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_40s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='40s'] span\")\n",
    "\n",
    "res_40s = []\n",
    "for i in range(len(keywords_40s)):\n",
    "    res_40s.append(keywords_40s[i].text)\n",
    "\n",
    "res_40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이미자',\n",
       " '유승현',\n",
       " '김현아 의원',\n",
       " '생생정보 이피디',\n",
       " '한센병',\n",
       " '문무일',\n",
       " '이재명 재판',\n",
       " '심재철',\n",
       " '김기태',\n",
       " '박흥식',\n",
       " '가수이미자나이',\n",
       " '누룽지통닭',\n",
       " '아미스타드',\n",
       " '생방송투데이',\n",
       " '참나무장작구이 누룽지통닭',\n",
       " '2tv 저녁 생생정보',\n",
       " '드라이카레',\n",
       " '이지윤 pd',\n",
       " '홍정욱',\n",
       " '절대그이']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_50s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='50s'] span\")\n",
    "\n",
    "res_50s = []\n",
    "for i in range(len(keywords_50s)):\n",
    "    res_50s.append(keywords_50s[i].text)\n",
    "\n",
    "res_50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql as pms\n",
    "\n",
    "cnx = pms.connect(host = \"plen-tutoring.mysql.database.azure.com\", \n",
    "                  port = 3306, \n",
    "                  user = \"plentir@plen-tutoring\", \n",
    "                  password = \"yjy990810!\", \n",
    "                  database = \"web_crawling\", \n",
    "                  charset = \"utf8\")\n",
    "\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk_table = \"\"\"CREATE TABLE Search_Keywords(\n",
    "ID INT UNSIGNED NOT NULL AUTO_INCREMENT, \n",
    "Date VARCHAR(10) NOT NULL, \n",
    "Time VARCHAR(8) NOT NULL, \n",
    "Keyword VARCHAR(255) NOT NULL, \n",
    "Rank INT NOT NULL, \n",
    "Category VARCHAR(20) NOT NULL, \n",
    "Source VARCHAR(50) NOT NULL, \n",
    "PRIMARY KEY(ID)\n",
    ") DEFAULT CHARSET = utf8 AUTO_INCREMENT = 1;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(mk_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
