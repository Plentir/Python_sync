{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 크롤링\n",
    "\n",
    "#### requests\n",
    "\n",
    "백그라운드에서 웹 크롤링을 진행.  \n",
    "\n",
    "    requests.get(\"url\")\n",
    "    \n",
    "입력한 URL을 호출함.\n",
    "\n",
    "**<HTTP 응답 번호>**\n",
    "- 200은 성공(205: ???)  \n",
    "- 300번대는 리다이렉션 메시지  \n",
    "- 400번대는 오류 메시지(403: 권한 없음, 404: 존재하지 않는 페이지)\n",
    "\n",
    "웹페이지 개발자 도구 이용  \n",
    "보통은 개발자 도구 페이지의 개체를 마우스 우클릭하면 나오는 XPath를 사용하여 코드 작성.\n",
    "\n",
    "#### bs4\n",
    "\n",
    "con.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib as ulb\n",
    "import requests as rqs\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "url = \"https://ko.wikipedia.org/wiki/조선_세종\"\n",
    "\n",
    "a = rqs.get(\"http://www.naver.com\")\n",
    "b = bs(a.content, \"lxml\")\n",
    "\n",
    "lst_kw = b.find_all(name = \"a\", class_ = \"ah_k\", attr = {\"data-clk\" : \"lve.keyword\"})\n",
    "b\n",
    "# lst_rk = b.fine_all(name = \"span\", class_ = \"ah_r\")\n",
    "\n",
    "# for line in :\n",
    "    # print(line.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬으로 매일 오전 8시, 오후 8시 실시간 검색어를 7일간 크롤링하기.  \n",
    "검색어의 순위 정보도 크롤링돼야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib as ulb\n",
    "import requests as rqs\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = [\"2019-05-16\", \"2019-05-17\", \"2019-05-18\", \"2019-05-19\", \"2019-05-20\", \"2019-05-21\", \"2019-05-22\", \"2019-05-23\", \"2019-05-27\"]\n",
    "time = [\"08%3A00%3A00\", \"20%3A00%3A00\"]\n",
    "\n",
    "url = \"https://datalab.naver.com/keyword/realtimeList.naver?datetime=%sT%s&where=main\" %(date[-1], time[0])\n",
    "print(url)\n",
    "\n",
    "rq_header = {\n",
    "    \"User-Agent\" : (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.134 Safari/537.36 Vivaldi/2.5.1525.40\")\n",
    "}\n",
    "\n",
    "page = rqs.get(url, headers = rq_header)\n",
    "page.encoding = \"utf-8\"\n",
    "print(page.url)\n",
    "# print(page.history)\n",
    "\n",
    "source_page = soup(page.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "날짜 범위 입력(YYYY-MM-DD ~ YYYY-MM-DD 형식)\n",
      "예시) 2019-01-01 ~ 2019-01-31\n",
      "입력:  2019-01-01 ~ 2019-01-31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-01 ~ 2019-01-31\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "시각 입력(hh:mm (24시간제) 형식, 따옴표로 구분)\n",
      "예시) 08:00, 20:00\n",
      "입력:  08:00, 20:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:00, 20:00\n"
     ]
    }
   ],
   "source": [
    "d = input(\"\"\"날짜 범위 입력(YYYY-MM-DD ~ YYYY-MM-DD 형식)\n",
    "예시) 2019-01-01 ~ 2019-01-31\n",
    "입력: \"\"\")\n",
    "\n",
    "dates = (d[0:10], d[-11:-1])\n",
    "\n",
    "print(dates)\n",
    "\n",
    "t = input(\"\"\"시각 입력(hh:mm (24시간제) 형식, 따옴표로 구분)\n",
    "예시) 08:00, 20:00\n",
    "입력: \"\"\")\n",
    "\n",
    "time = []\n",
    "\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_sql(d, t, k, r, c, s):\n",
    "    dict_age = {\"all\" : \"전체\", \"10s\" : \"10대\", \"20s\" : \"20대\", \"30s\" : \"30대\", \"40s\" : \"40대\", \"50s\" : \"50대 이상\"}\n",
    "    \n",
    "    dict_time = {\"08%3A00%3A00\": \"08:00\", \"20%3A00%3A00\": \"20:00\"}\n",
    "    \n",
    "    sql = \"\"\"INSERT INTO Search_Keywords(Date, Time, Keyword, Rank, Category, Source)\n",
    "VALUES ('%s', '%s', '%s', '%s', '%s', '%s');\"\"\" %(d, dict_time[t], k, r, dict_age[c], s)\n",
    "        \n",
    "    return sql\n",
    "    \n",
    "    \n",
    "def crawler(dates, times):\n",
    "    rq_header = {\n",
    "    \"User-Agent\" : (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.134 Safari/537.36 Vivaldi/2.5.1525.40\")\n",
    "    }\n",
    "    \n",
    "    ages = [\"all\", \"10s\", \"20s\", \"30s\", \"40s\", \"50s\"]\n",
    "    \n",
    "    for d in dates:  # 일자별로 키워드 수집\n",
    "        for t in times:  # 시간별로 키워드 수집\n",
    "            url = \"https://datalab.naver.com/keyword/realtimeList.naver?datetime=%sT%s&where=main\" %(d, t)\n",
    "            \n",
    "            page = rqs.get(url, headers = rq_header)\n",
    "            page.encoding = \"utf-8\"\n",
    "            \n",
    "            source_page = soup(page.content, \"lxml\")\n",
    "            \n",
    "            for i in range(len(ages)):  # 나이별로 키워드 수집\n",
    "                keywords = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='%s'] span\" %ages[i])\n",
    "                \n",
    "                kwds_txt = []\n",
    "                for j in range(len(keywords)):  # 키워드(텍스트)만 추출하여 txt에 추가\n",
    "                    kwds_txt.append(keywords[j].text)\n",
    "                \n",
    "                for j in range(len(kwds_txt)):\n",
    "                    sql = export_to_sql(d, t, kwds_txt[j], j + 1, ages[i], \"Naver\")  # Date, Time, Keyword, Rank, Category, Source\n",
    "                    # cursor.execute(sql)\n",
    "    \n",
    "    print(\"end\")\n",
    "\n",
    "    # cnx.commit()\n",
    "    print(\"커밋됨.\")\n",
    "\n",
    "    # cnx.close()\n",
    "    print(\"종료됨.\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"2019-05-16\", \"2019-05-17\", \"2019-05-18\", \"2019-05-19\", \"2019-05-20\", \"2019-05-21\", \"2019-05-22\", \"2019-05-23\"]\n",
    "\n",
    "times = [\"08%3A00%3A00\", \"20%3A00%3A00\"]\n",
    "\n",
    "crawler([\"2019-05-23\"], [\"08%3A00%3A00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keywords = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank > .rank_inner *\")\n",
    "# rank = source_page\n",
    "keywords_all = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='all'] span\")\n",
    "\n",
    "res_all = []\n",
    "for i in range(len(keywords_all)):\n",
    "    res_all.append(keywords_all[i].text)\n",
    "\n",
    "res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_10s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='10s'] span\")\n",
    "\n",
    "res_10s = []\n",
    "for i in range(len(keywords_10s)):\n",
    "    res_10s.append(keywords_10s[i].text)\n",
    "\n",
    "res_10s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_20s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='20s'] span\")\n",
    "\n",
    "res_20s = []\n",
    "for i in range(len(keywords_20s)):\n",
    "    res_20s.append(keywords_20s[i].text)\n",
    "\n",
    "res_20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_30s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='30s'] span\")\n",
    "\n",
    "res_30s = []\n",
    "for i in range(len(keywords_30s)):\n",
    "    res_30s.append(keywords_30s[i].text)\n",
    "\n",
    "res_30s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_40s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='40s'] span\")\n",
    "\n",
    "res_40s = []\n",
    "for i in range(len(keywords_40s)):\n",
    "    res_40s.append(keywords_40s[i].text)\n",
    "\n",
    "res_40s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_50s = source_page.select(\".section_lst_area.carousel_area.lst_narrow .keyword_rank div[data-age='50s'] span\")\n",
    "\n",
    "res_50s = []\n",
    "for i in range(len(keywords_50s)):\n",
    "    res_50s.append(keywords_50s[i].text)\n",
    "\n",
    "res_50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql as pms\n",
    "\n",
    "cnx = pms.connect(host = \"plen-tutoring.mysql.database.azure.com\", \n",
    "                  port = 3306, \n",
    "                  user = \"plentir@plen-tutoring\", \n",
    "                  password = \"yjy990810!\", \n",
    "                  database = \"web_crawling\", \n",
    "                  charset = \"utf8\")\n",
    "\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_table = \"\"\"CREATE TABLE Search_Keywords(\n",
    "ID INT UNSIGNED NOT NULL AUTO_INCREMENT, \n",
    "Date VARCHAR(10) NOT NULL, \n",
    "Time VARCHAR(8) NOT NULL, \n",
    "Keyword VARCHAR(255) NOT NULL, \n",
    "Rank INT NOT NULL, \n",
    "Category VARCHAR(20) NOT NULL, \n",
    "Source VARCHAR(50) NOT NULL, \n",
    "PRIMARY KEY(ID)\n",
    ") DEFAULT CHARSET = utf8 AUTO_INCREMENT = 1;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(mk_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
